{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac526311-9702-468b-b634-ee68933f5b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import joblib\n",
    "import json\n",
    "\n",
    "from ezkl import export"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d2a31d49-87e0-4a9d-b1ab-def594582969",
   "metadata": {},
   "source": [
    "## Read the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77efc4cb-d1b3-492d-8f53-28eb2537b2ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12696, 71)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>apy-Var1Day</th>\n",
       "      <th>tvlUsd-Var1Day</th>\n",
       "      <th>apy-chain-mean-Var1Day</th>\n",
       "      <th>tvlUsd-chain-mean-Var1Day</th>\n",
       "      <th>apy-protocol-mean-Var1Day</th>\n",
       "      <th>tvlUsd-protocol-mean-Var1Day</th>\n",
       "      <th>apy-token-mean-Var1Day</th>\n",
       "      <th>tvlUsd-token-mean-Var1Day</th>\n",
       "      <th>apy-chain-max-Var1Day</th>\n",
       "      <th>...</th>\n",
       "      <th>apy-protocol-mean-Var30Day</th>\n",
       "      <th>tvlUsd-protocol-mean-Var30Day</th>\n",
       "      <th>apy-token-mean-Var30Day</th>\n",
       "      <th>tvlUsd-token-mean-Var30Day</th>\n",
       "      <th>apy-chain-max-Var30Day</th>\n",
       "      <th>apy-protocol-max-Var30Day</th>\n",
       "      <th>apy-token-max-Var30Day</th>\n",
       "      <th>tvlUsd-chain-sum-Var30Day</th>\n",
       "      <th>tvlUsd-protocol-sum-Var30Day</th>\n",
       "      <th>tvlUsd-token-sum-Var30Day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.007886</td>\n",
       "      <td>-0.002881</td>\n",
       "      <td>0.384474</td>\n",
       "      <td>0.012158</td>\n",
       "      <td>0.008700</td>\n",
       "      <td>0.002458</td>\n",
       "      <td>0.074924</td>\n",
       "      <td>0.012354</td>\n",
       "      <td>0.619913</td>\n",
       "      <td>...</td>\n",
       "      <td>0.528504</td>\n",
       "      <td>0.212078</td>\n",
       "      <td>1.080723</td>\n",
       "      <td>0.087964</td>\n",
       "      <td>2.729201</td>\n",
       "      <td>0.353595</td>\n",
       "      <td>1.641604</td>\n",
       "      <td>0.040766</td>\n",
       "      <td>0.212078</td>\n",
       "      <td>0.087964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.002264</td>\n",
       "      <td>0.202158</td>\n",
       "      <td>0.034465</td>\n",
       "      <td>-0.057477</td>\n",
       "      <td>0.015966</td>\n",
       "      <td>0.084087</td>\n",
       "      <td>0.015578</td>\n",
       "      <td>0.021917</td>\n",
       "      <td>...</td>\n",
       "      <td>0.511465</td>\n",
       "      <td>0.018395</td>\n",
       "      <td>4.537764</td>\n",
       "      <td>-0.006988</td>\n",
       "      <td>0.321799</td>\n",
       "      <td>0.791096</td>\n",
       "      <td>11.122229</td>\n",
       "      <td>0.097451</td>\n",
       "      <td>0.018395</td>\n",
       "      <td>-0.006988</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   target  apy-Var1Day  tvlUsd-Var1Day  apy-chain-mean-Var1Day  \\\n",
       "0       0     0.007886       -0.002881                0.384474   \n",
       "1       0     0.000000       -0.002264                0.202158   \n",
       "\n",
       "   tvlUsd-chain-mean-Var1Day  apy-protocol-mean-Var1Day  \\\n",
       "0                   0.012158                   0.008700   \n",
       "1                   0.034465                  -0.057477   \n",
       "\n",
       "   tvlUsd-protocol-mean-Var1Day  apy-token-mean-Var1Day  \\\n",
       "0                      0.002458                0.074924   \n",
       "1                      0.015966                0.084087   \n",
       "\n",
       "   tvlUsd-token-mean-Var1Day  apy-chain-max-Var1Day  ...  \\\n",
       "0                   0.012354               0.619913  ...   \n",
       "1                   0.015578               0.021917  ...   \n",
       "\n",
       "   apy-protocol-mean-Var30Day  tvlUsd-protocol-mean-Var30Day  \\\n",
       "0                    0.528504                       0.212078   \n",
       "1                    0.511465                       0.018395   \n",
       "\n",
       "   apy-token-mean-Var30Day  tvlUsd-token-mean-Var30Day  \\\n",
       "0                 1.080723                    0.087964   \n",
       "1                 4.537764                   -0.006988   \n",
       "\n",
       "   apy-chain-max-Var30Day  apy-protocol-max-Var30Day  apy-token-max-Var30Day  \\\n",
       "0                2.729201                   0.353595                1.641604   \n",
       "1                0.321799                   0.791096               11.122229   \n",
       "\n",
       "   tvlUsd-chain-sum-Var30Day  tvlUsd-protocol-sum-Var30Day  \\\n",
       "0                   0.040766                      0.212078   \n",
       "1                   0.097451                      0.018395   \n",
       "\n",
       "   tvlUsd-token-sum-Var30Day  \n",
       "0                   0.087964  \n",
       "1                  -0.006988  \n",
       "\n",
       "[2 rows x 71 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../sample-data/data.csv.gz', compression='gzip')\n",
    "print(data.shape)\n",
    "data.head(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0c5f90d5-71cb-4152-85fe-5c7fd466f020",
   "metadata": {},
   "source": [
    "## Split, scale and create Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f1c6f06-90f6-4e7b-a479-d6b8f49a2d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:, 1:]\n",
    "y = data.iloc[:, 0]\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "joblib.dump(scaler, 'X_scaler.joblib')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fbf42050-2ab3-4eb9-8aa6-f9fe0aefcc20",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f00c6a3-f316-4836-b920-e82d9d0846bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryClassifier(nn.Module):\n",
    "    def __init__(self, hidden_size, input_size):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size*2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(hidden_size*2, hidden_size)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.output = nn.Linear(hidden_size, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.output(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6545fd78-8ce4-48a9-9898-e0d8f2040a52",
   "metadata": {},
   "source": [
    "## Export model before training\n",
    "\n",
    "This works when we run the proof, but it has aleatory weights, its not usefull\n",
    "\n",
    "Just take into account its exporting a random set of values in the shape of the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cfe133f1-6183-4b7f-9c62-9185a6e1dac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ Diagnostic Run torch.onnx.export version 2.0.0 ================\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 512\n",
    "learning_rate = 0.001\n",
    "input_size = X_train_tensor.shape[1]\n",
    "\n",
    "model = BinaryClassifier(hidden_size, input_size)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "circuit = BinaryClassifier(hidden_size, input_size)\n",
    "export(circuit, input_shape=[input_size], onnx_filename=\"../python-output/network-before-train.onnx\", input_filename=\"../python-output/dummy-input-before-train.json\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "64e03591-e0c4-43f8-8745-0f2f7a825192",
   "metadata": {},
   "source": [
    "______________________"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e2c5dbba-df87-408c-b4ba-3c178d57fa35",
   "metadata": {},
   "source": [
    "## Train the same model in 1000 epochs to update weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6da705bf-ae2d-421c-8d68-ba189d94678b",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1000\n",
    "\n",
    "input_size = X_train_tensor.shape[1]\n",
    "\n",
    "# Initialize the model\n",
    "model = BinaryClassifier(hidden_size, input_size)\n",
    "\n",
    "# Define the loss function and the optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = model(X_train_tensor).squeeze()\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "\n",
    "    # Backward and optimize\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "23ef0b81-1f5a-4142-b5ba-d1ee7a4aa89c",
   "metadata": {},
   "source": [
    "## Export the trained model\n",
    "\n",
    "This doesn't works when we run the proof, even with random values generated in the json file\n",
    "\n",
    "Also exporting a random set of values in the shape of the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "79cd1979-bf73-4f0e-9271-5fc18fd2ee97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ Diagnostic Run torch.onnx.export version 2.0.0 ================\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "export(model, input_shape=[input_size], onnx_filename=\"../python-output/network-after-train.onnx\", input_filename=\"../python-output/dummy-input-after-train.json\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "90c85dd8-efc4-4242-8f3a-83d53a7b1344",
   "metadata": {},
   "source": [
    "____________"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "030341af-36e6-48f2-a2fc-5c2d27e1669d",
   "metadata": {},
   "source": [
    "## Modify the export function so it can work for an input_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad904fc5-bfe4-4ea6-8280-9056d83eec6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exportar(torch_model, input_array, input_filename):\n",
    "    x = torch.tensor(input_array)\n",
    "    new_shape = tuple([1] + list(x.shape))\n",
    "    x = torch.reshape(x, new_shape)\n",
    "    x = x.type(torch.float32)\n",
    "\n",
    "    torch_out = torch_model(x)\n",
    "\n",
    "    data_array = ((x).detach().numpy()).reshape([-1]).tolist()\n",
    "\n",
    "    data = dict(input_shapes=[len(input_array)],\n",
    "                input_data=[data_array],\n",
    "                output_data=[((o).detach().numpy()).reshape([-1]).tolist() for o in torch_out])\n",
    "    # Serialize data into file:\n",
    "    json.dump(data, open(input_filename, 'w'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6c5e6f24-3300-45fe-8c91-532c0f3def8e",
   "metadata": {},
   "source": [
    "## Export the input.json with real test values to proof\n",
    "\n",
    "It doesn't work either, but it may be a problem with the export of the model and not with the input.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "54a45ad0-a999-4ed2-847e-dc24bfaa2296",
   "metadata": {},
   "outputs": [],
   "source": [
    "exportar(model, X_test[0], '../python-output/real-input-after-train.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
